model: Qwen/Qwen3-Next-80B-A3B-Instruct
backend: vllm
endpoint: ???
generation_kwargs:
  max_completion_tokens: 256
  temperature: 0.7
  top_p: 0.8
